{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Exploration\n",
    "Here we explore the method suggested in `arXiv:1803.01485v3`. We obtain image representations by taking the output of the penultimate layer of a pre-trained model.  \n",
    "\n",
    "In this notebook we use the [Caltech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) dataset and the `ResNet50` model taken from the Keras Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for each picture and get representation\n",
    "def get_representations(path, a=None, b=None):\n",
    "    features_list = []\n",
    "    for img_name in os.listdir(path)[a:b]:\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img = image.load_img(img_path,  target_size=(300,300))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features = model.predict(x)\n",
    "        features_list.append(features[0])\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pagoda', 'yin_yang', 'gerenuk', 'emu', 'binocular', 'pizza', 'dollar_bill', 'kangaroo', 'octopus', 'ibis', 'trilobite', 'cup', 'BACKGROUND_Google', 'stop_sign', 'stegosaurus', 'water_lilly', 'Faces_easy', 'flamingo_head', 'schooner', 'car_side', 'tick', 'ant', 'garfield', 'platypus', 'ketch', 'Faces', 'snoopy', 'lamp', 'headphone', 'dalmatian', 'wild_cat', 'ceiling_fan', 'umbrella', 'cellphone', 'stapler', 'pigeon', 'helicopter', 'camera', 'dragonfly', 'elephant', 'okapi', 'flamingo', 'Leopards', 'electric_guitar', 'crocodile_head', 'inline_skate', 'panda', 'scorpion', 'saxophone', 'watch', 'chandelier', 'cannon', 'crayfish', 'scissors', 'anchor', 'buddha', 'lotus', 'bonsai', 'strawberry', 'joshua_tree', 'mayfly', 'grand_piano', 'metronome', 'pyramid', 'accordion', 'bass', 'crab', 'hawksbill', 'cougar_body', 'mandolin', 'starfish', 'laptop', 'chair', 'rhino', 'euphonium', 'menorah', 'windsor_chair', 'butterfly', 'crocodile', 'beaver', 'wheelchair', 'brontosaurus', 'revolver', 'cougar_face', 'soccer_ball', 'barrel', 'ewer', 'lobster', 'sea_horse', 'gramophone', 'ferry', 'llama', 'wrench', 'nautilus', 'minaret', 'brain', 'rooster', 'sunflower', 'dolphin', 'airplanes', 'hedgehog', 'Motorbikes']\n"
     ]
    }
   ],
   "source": [
    "# Check classes\n",
    "DATA_PATH = 'data'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = 'bonsai'\n",
    "class2 = 'ewer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Representations by Class and split to train/test\n",
    "class1_train = get_representations(os.path.join(DATA_PATH, class1), b=40)\n",
    "class2_train = get_representations(os.path.join(DATA_PATH, class2), b=40)\n",
    "\n",
    "class1_test = get_representations(os.path.join(DATA_PATH, class1), a=-25)\n",
    "class2_test = get_representations(os.path.join(DATA_PATH, class2), a=-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train X,y vectors from class representations\n",
    "X_train = np.concatenate((class1_train, class2_train))\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "\n",
    "# Binary Labels\n",
    "class1_labels_tr = np.ones(len(class1_train))\n",
    "class2_labels_tr = np.zeros(len(class2_train))\n",
    "y_train = np.concatenate((class1_labels_tr, class2_labels_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test X,y vectors from class representations\n",
    "X_test = np.concatenate((class1_test, class2_test))\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "# Binary Labels\n",
    "class1_labels_ts = np.ones(len(class1_test))\n",
    "class2_labels_ts = np.zeros(len(class2_test))\n",
    "y_test = np.concatenate((class1_labels_ts, class2_labels_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto', kernel='sigmoid'))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a C-Support Vector Classification from sklearn\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='sigmoid', gamma='auto'))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}%\".format(100*(preds == y_test).sum()/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_env",
   "language": "python",
   "name": "proj_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
